import json
import pycountry
from sharedutils import stdlog, errlog
from datetime import datetime
import os, hashlib
from countryinfo import CountryInfo
import requests
from bs4 import BeautifulSoup

def format_date(date_string):
    try:
        date_obj = datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S.%f')
        return date_obj.strftime('%Y-%m-%d')
    except ValueError:
        errlog('Error generating country page')

def count_post_titles_by_country(country_code):
    with open('posts.json', 'r') as file:
        posts_data = json.load(file)    
    count = 0
    for post in posts_data:
        if post.get('country') == country_code:
            count += 1
    return count


print(
'''
   _______________                        |*\_/*|________
  |  ___________  |                      ||_/-\_|______  |
  | |           | |                      | |           | |
  | |   0   0   | |                      | |   0   0   | |
  | |     -     | |                      | |     -     | |
  | |   \___/   | |                      | |   \___/   | |
  | |___     ___| |                      | |___________| |
  |_____|\_/|_____|                      |_______________|
    _|__|/ \|_|_.............üíî.............._|________|_
   / ********** \                          / ********** \ 
 /  ************  \   ransomware.live     /  ************  \ 
--------------------                    --------------------
'''
)
stdlog('Generating countries')



# Read the JSON file
with open('posts.json', 'r') as file:
    data = json.load(file)

# Extract country codes from the 'country' field in each post
country_codes = [post.get('country') for post in data if post.get('country')]

# Get unique country codes
unique_country_codes = set(country_codes)

# Get country names based on country codes, filtering out invalid codes
valid_countries = [pycountry.countries.get(alpha_2=code) for code in unique_country_codes if pycountry.countries.get(alpha_2=code)]


# Sort valid country names alphabetically
sorted_countries = sorted(valid_countries, key=lambda x: x.name)

num_countries = len(sorted_countries)

# Generate image URLs for each country within the country name
image_urls = [f"![{country.alpha_2.upper()}](https://images.ransomware.live/flags/{country.alpha_2.upper()}.svg ':size=32x24 :no-zoom') {country.name}" for country in sorted_countries]

table_rows = []
for country in sorted_countries:
    country_name = country.name
    country_code = country.alpha_2.lower()
    country_link = f"[{country_name}](/country/{country_code})"
    country_count = count_post_titles_by_country(country.alpha_2.upper())
    flag_image = f"![{country.alpha_2.upper()}](https://images.ransomware.live/flags/{country.alpha_2.upper()}.svg ':size=32x24 :no-zoom')"
    table_rows.append(f"{flag_image} {country_link} ({country_count}) ")

# Calculate the number of rows needed in the table
num_cols = 4
num_rows = (len(image_urls) + num_cols - 1) // num_cols  # Round up division to determine the number of rows

# Format the combined country names and image URLs into a Markdown table with 5 columns
markdown_table = "# üåç Ransomware's victims by country\n\n"

markdown_table += "> [!INFO]\n"
markdown_table += "> The country identification on Ransomware.live might not always be accurate as it uses artificial intelligence to deduce the location of victims.\n"
markdown_table += "> If you want to notify me about any mistake, you can either [open an issue](https://github.com/JMousqueton/ransomware.live/issues) on the github repository of Ransomware.live or [contact me](https://static.ransomware.live/contact.html).\n\n"


markdown_table += "|   |   |   |   | \n"
markdown_table += "|---|---|---|---|\n"
#
for i in range(num_rows):
    start = i * num_cols
    end = min(start + num_cols, len(table_rows))
    row_data = table_rows[start:end]
    row = "| " + " | ".join(row_data) + " " * (11 * num_cols - len(row_data) * 11 - 1) + "|\n"  # Adjust for varying data size
    markdown_table += row

markdown_table +="\n\n"
markdown_table += str(len(sorted_countries))
markdown_table += " attacked countries detected"

# Save the Markdown table in the ./docs/ directory
output_file_path = './docs/country.md'

with open(output_file_path, 'w') as table_file:
    table_file.write(markdown_table)

# Load the JSON data from the file
with open('eucert.json') as json_file:
    cert = json.load(json_file)

def get_cert_info_by_country(country_code):
    cert_info = []
    for entry in cert['data']:
        if entry['country-code'] == country_code:
            cert_info.append({
                'team_name': entry['team-name'],
                'website': entry['website'],
                'email': entry['email']
            })
    return cert_info

def get_teams_info_by_country(country_code, html_content):
    soup = BeautifulSoup(html_content, 'html.parser')

    certs_info = []

    # Find all rows in the table body
    rows = soup.find('table', {'class': 'data-preview'}).find('tbody').find_all('tr')

    # Extracting information from each row based on the provided country code
    for row in rows:
        country = row.find('span', {'class': 'flag'}).text
        country = country.lstrip()
        if country.lower() == country_code.lower():
            link = row.find('a').get('href')
            name = row.find('a').text
            row_id = row.get('id')
            certs_info.append({
                'country': country,
                'link': link,
                'name': name,
                'row_id': row_id
            })
    return certs_info

## Create page per country 
def create_country_victims_file(country_code, victims_data,html_content):
    country = pycountry.countries.get(alpha_2=country_code.upper())
    NowTime=datetime.now()
    if country:
        country_name = country.name
        file_path = f"./docs/country/{country_code.lower()}.md"
        with open(file_path, 'w') as country_file:
            country_file.write(f"# Ransomware's victimss in {country_name} ![{country_code.upper()}](https://images.ransomware.live/flags/{country_code.upper()}.svg)\n\n")
            try:
                country = CountryInfo(country_code)
                try: 
                    capital = country.capital()
                except:
                    capital = 'N/A' 
                try:
                    population = str("{:,}".format(country.population())) + " people" 
                except: 
                    population = 'N/A'
                try:
                    area = str("{:,}".format(country.area())) + " square kilometers" 
                except: 
                    area = "N/A"
                try:
                    timezones = ', '.join(country.timezones()) 
                except:
                    timezones = 'N/A'   
            except:
                stdlog('Error getting info for country ' + country_name + ' (' + country_code + ')')    

            ### GET European cert
            if country_code.lower() == 'uk':
                country_code == 'GB'
            certs_for_country = get_cert_info_by_country(country_code.lower())
            if certs_for_country:
                certlist = '| CERT name | Website | Email |\n'
                certlist += '|---|---|---|\n'
                for cert in certs_for_country:
                    #certlist += '|' +  cert['team_name'] + '|' + cert['website'] + '|' + cert['email'].replace('@','üåÄ')+'\n'
                    certlist += '| ' +  cert['team_name'] + ' | ' + cert['website'] + ' | ' + cert['email']+' | \n'
            else:
                certs = get_teams_info_by_country(country_code, html_content)
                if certs:
                    certlist = '| CERT name | Link |\n'
                    certlist += '|---|---|\n'

                    # Displaying the extracted information
                    for cert in certs:
                        certlist += '| ' +  cert['name'] + ' | https://www.first.org'+cert['link']+ ' |\n' 
                else:
                    stdlog(f"No CERTs found for country code {country_code.upper()}.")
                    certlist= 'No CERT/CSIRT found'

            country_file.write('### Country Information \n')
            country_file.write('<!-- tabs:start -->\n')
            country_file.write('#### **Capital**\n')
            country_file.write(capital+"\n")
            country_file.write('#### **Population**\n') 
            country_file.write(population+"\n")
            country_file.write('#### **Area**\n')
            country_file.write(area+"\n")
            country_file.write('#### **Time Zones**\n') 
            country_file.write(timezones+"\n")
            country_file.write('#### **CERTs**\n') 
            country_file.write(certlist+"\n")
            country_file.write('<!-- tabs:end -->\n') 


            country_file.write('\n \n')

            country_file.write(f"> [!INFO]\n")
            country_file.write(f"> The country identification on Ransomware.live might not always be accurate as it uses artificial intelligence to deduce the location of victims.\n")
            country_file.write(f"> If you want to notify me about any mistake, you can either [open an issue](https://github.com/JMousqueton/ransomware.live/issues) on the github repository of Ransomware.live or [contact me](https://static.ransomware.live/contact.html).\n\n")

            counter = 0 
            country_file.write(f"\n| Discovered date | Attack date | Victim | Ransomware Group | üì∏ |\n")
            country_file.write(f"|---|---|---|---|---|\n")
            for victim in victims_data:
                if victim['discovered_date'] == victim['published_date']:
                    victim['published_date'] = ' '
                # screenpost='‚ùå'
                screenpost=' '
                if victim['post_url'] is not None: 
                     # Create an MD5 hash object
                    hash_object = hashlib.md5()
                    # Update the hash object with the string
                    hash_object.update(victim['post_url'].encode('utf-8'))
                    # Get the hexadecimal representation of the hash
                    hex_digest = hash_object.hexdigest()
                    if os.path.exists('docs/screenshots/posts/'+hex_digest+'.png'):
                        screenpost='<a href="https://images.ransomware.live/screenshots/posts/' + hex_digest + '.png" target=_blank>üëÄ</a>'
                country_file.write(f"|{victim['discovered_date']}|{victim['published_date']}|[{victim['name']}](https://google.com/search?q={victim['name'].replace(' ','+')})|[{victim['group_name']}](group/{victim['group_name']})| {screenpost}|\n")
                counter += 1 
            country_file.write(f"\n\n{counter} victims found\n\n")
            country_file.write('Last update : _'+ NowTime.strftime('%A %d/%m/%Y %H.%M') + ' (UTC)_')



# Load posts from JSON file
with open('posts.json', 'r') as file:
    posts_data = json.load(file)

# Group victims by country code
victims_by_country = {}
for post in posts_data:
    country_code = post.get('country')
    victim_name = post.get('post_title')
    published_date = format_date(post.get('published'))
    post_url = post.get('post_url', '')
    group_name = post.get('group_name')
    discovered_date = format_date(post.get('discovered'))

    if country_code and victim_name and published_date and discovered_date and group_name:
        if country_code not in victims_by_country:
            victims_by_country[country_code] = []
        victims_by_country[country_code].append({
            'name': victim_name,
            'published_date': published_date,
            'discovered_date': discovered_date,
            'post_url': post_url, 
            'group_name': group_name
        })


# Fetch HTML content from the URL
url = 'https://www.first.org/members/teams/'
response = requests.get(url)
html_content = response.content

# Sort victims by published_date in descending order
for country_code, victims_data in victims_by_country.items():
    victims_by_country[country_code] = sorted(victims_data, key=lambda x: datetime.strptime(x['discovered_date'], '%Y-%m-%d'), reverse=True)

# Create individual country files for victims
for country_code, victims_data in victims_by_country.items():
    stdlog('Create page for ' + country_code)
    create_country_victims_file(country_code, victims_data,html_content)

